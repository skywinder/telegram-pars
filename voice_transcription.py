"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∏ –≤–∏–¥–µ–æ—Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ Telegram
"""
import os
import asyncio
from typing import Dict, List, Optional
import whisper
import speech_recognition as sr
from pydub import AudioSegment
from telethon.tl.types import MessageMediaDocument, MessageMediaPhoto
import config

class VoiceTranscriber:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    """
    
    def __init__(self, use_whisper: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–µ—Ä–∞
        
        Args:
            use_whisper: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Whisper AI (–±–æ–ª–µ–µ —Ç–æ—á–Ω–æ) –∏–ª–∏ SpeechRecognition
        """
        self.use_whisper = use_whisper
        self.whisper_model = None
        self.recognizer = None
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.temp_dir = os.path.join(config.OUTPUT_DIR, 'voice_temp')
        if not os.path.exists(self.temp_dir):
            os.makedirs(self.temp_dir)
    
    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if self.use_whisper:
            print("üîä –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper AI...")
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper (–º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å —Ä–∞–∑–º–µ—Ä: tiny, base, small, medium, large)
            self.whisper_model = whisper.load_model("base")  # –ö–æ–º–ø—Ä–æ–º–∏—Å—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ
            print("‚úÖ Whisper –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        else:
            print("üîä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º SpeechRecognition...")
            self.recognizer = sr.Recognizer()
            print("‚úÖ SpeechRecognition –≥–æ—Ç–æ–≤")
    
    async def download_voice_message(self, client, message) -> Optional[str]:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        
        Args:
            client: Telegram –∫–ª–∏–µ–Ω—Ç
            message: –°–æ–æ–±—â–µ–Ω–∏–µ —Å –≥–æ–ª–æ—Å–æ–≤–∫–æ–π
            
        Returns:
            –ü—É—Ç—å –∫ —Å–∫–∞—á–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É –∏–ª–∏ None
        """
        if not message.media:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –º–µ–¥–∏–∞
        if hasattr(message.media, 'document'):
            document = message.media.document
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º MIME —Ç–∏–ø
            if document.mime_type not in ['audio/ogg', 'audio/mpeg', 'video/mp4', 'audio/wav']:
                return None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if 'ogg' in document.mime_type:
                ext = '.ogg'
            elif 'mp4' in document.mime_type:
                ext = '.mp4'
            elif 'wav' in document.mime_type:
                ext = '.wav'
            else:
                ext = '.mp3'
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            filename = f"voice_{message.id}_{message.date.strftime('%Y%m%d_%H%M%S')}{ext}"
            filepath = os.path.join(self.temp_dir, filename)
            
            try:
                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
                await client.download_media(message.media, filepath)
                print(f"üì• –°–∫–∞—á–∞–Ω: {filename}")
                return filepath
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {filename}: {e}")
                return None
        
        return None
    
    def convert_to_wav(self, input_file: str) -> Optional[str]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ WAV —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        
        Args:
            input_file: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            
        Returns:
            –ü—É—Ç—å –∫ WAV —Ñ–∞–π–ª—É –∏–ª–∏ None
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            base_name = os.path.splitext(input_file)[0]
            output_file = f"{base_name}.wav"
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é pydub
            if input_file.endswith('.ogg'):
                audio = AudioSegment.from_ogg(input_file)
            elif input_file.endswith('.mp4'):
                audio = AudioSegment.from_file(input_file, format="mp4")
            elif input_file.endswith('.mp3'):
                audio = AudioSegment.from_mp3(input_file)
            else:
                # –£–∂–µ WAV
                return input_file
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            audio = audio.set_frame_rate(16000).set_channels(1)  # –ú–æ–Ω–æ, 16kHz
            audio.export(output_file, format="wav")
            
            print(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ WAV: {os.path.basename(output_file)}")
            return output_file
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ {input_file}: {e}")
            return None
    
    def transcribe_with_whisper(self, wav_file: str) -> Optional[Dict]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é Whisper AI
        
        Args:
            wav_file: –ü—É—Ç—å –∫ WAV —Ñ–∞–π–ª—É
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        """
        try:
            if not self.whisper_model:
                self.initialize()
            
            print(f"ü§ñ Whisper –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç: {os.path.basename(wav_file)}")
            result = self.whisper_model.transcribe(wav_file)
            
            return {
                'method': 'whisper',
                'text': result['text'].strip(),
                'language': result.get('language', 'unknown'),
                'confidence': 'high',  # Whisper –æ–±—ã—á–Ω–æ –æ—á–µ–Ω—å —Ç–æ—á–Ω—ã–π
                'segments': result.get('segments', [])
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Whisper: {e}")
            return None
    
    def transcribe_with_speech_recognition(self, wav_file: str) -> Optional[Dict]:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é SpeechRecognition
        
        Args:
            wav_file: –ü—É—Ç—å –∫ WAV —Ñ–∞–π–ª—É
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        """
        try:
            if not self.recognizer:
                self.initialize()
            
            print(f"üé§ SpeechRecognition –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç: {os.path.basename(wav_file)}")
            
            with sr.AudioFile(wav_file) as source:
                audio = self.recognizer.record(source)
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –¥–≤–∏–∂–∫–∏
            results = []
            
            # Google Speech Recognition (—Ç—Ä–µ–±—É–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç)
            try:
                text = self.recognizer.recognize_google(audio, language='ru-RU')
                results.append({
                    'engine': 'google',
                    'text': text,
                    'confidence': 'medium'
                })
            except:
                pass
            
            # Offline Sphinx (–º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞)
            try:
                text = self.recognizer.recognize_sphinx(audio, language='ru-RU')
                results.append({
                    'engine': 'sphinx',
                    'text': text,
                    'confidence': 'low'
                })
            except:
                pass
            
            if results:
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (Google –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ)
                best_result = results[0]
                return {
                    'method': 'speech_recognition',
                    'text': best_result['text'],
                    'engine': best_result['engine'],
                    'confidence': best_result['confidence'],
                    'alternatives': results[1:] if len(results) > 1 else []
                }
            else:
                return None
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ SpeechRecognition: {e}")
            return None
    
    def transcribe_audio_file(self, audio_file: str) -> Optional[Dict]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        
        Args:
            audio_file: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        """
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        wav_file = self.convert_to_wav(audio_file)
        if not wav_file:
            return None
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        if self.use_whisper:
            result = self.transcribe_with_whisper(wav_file)
        else:
            result = self.transcribe_with_speech_recognition(wav_file)
        
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        try:
            if wav_file != audio_file:  # –ù–µ —É–¥–∞–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –µ—Å–ª–∏ –æ–Ω —É–∂–µ WAV
                os.remove(wav_file)
            os.remove(audio_file)
        except:
            pass
        
        return result
    
    async def transcribe_voice_messages(self, client, messages: List) -> Dict:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –≤—Å–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å–ø–∏—Å–∫–∞
        
        Args:
            client: Telegram –∫–ª–∏–µ–Ω—Ç
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
        """
        results = {
            'total_voice_messages': 0,
            'successfully_transcribed': 0,
            'failed_transcriptions': 0,
            'transcriptions': {}
        }
        
        for message in messages:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ/–≤–∏–¥–µ–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
            if not message.media:
                continue
                
            if hasattr(message.media, 'document'):
                doc = message.media.document
                if not doc.mime_type or not any(t in doc.mime_type for t in ['audio', 'video']):
                    continue
                
                results['total_voice_messages'] += 1
                print(f"\nüé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {message.id}...")
                
                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
                audio_file = await self.download_voice_message(client, message)
                if not audio_file:
                    results['failed_transcriptions'] += 1
                    continue
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
                transcription = self.transcribe_audio_file(audio_file)
                if transcription:
                    results['transcriptions'][message.id] = {
                        'message_id': message.id,
                        'date': message.date.isoformat(),
                        'sender_id': message.sender_id,
                        'transcription': transcription,
                        'original_duration': getattr(message.media.document, 'duration', 0)
                    }
                    results['successfully_transcribed'] += 1
                    print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–æ: '{transcription['text'][:50]}...'")
                else:
                    results['failed_transcriptions'] += 1
                    print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {message.id}")
        
        return results
    
    def cleanup_temp_files(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        try:
            for file in os.listdir(self.temp_dir):
                file_path = os.path.join(self.temp_dir, file)
                os.remove(file_path)
            print("üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ main_advanced.py
async def transcribe_voice_messages_menu(parser, transcriber):
    """
    –ú–µ–Ω—é –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    """
    print("\nüé§ –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø –ì–û–õ–û–°–û–í–´–• –°–û–û–ë–©–ï–ù–ò–ô")
    print("‚ö†Ô∏è –≠—Ç–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è!")
    
    # –í—ã–±–æ—Ä —á–∞—Ç–∞
    chats = await parser.get_chats_list()
    print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ —á–∞—Ç—ã:")
    for i, chat in enumerate(chats[:10], 1):
        print(f"{i}. {chat['name']}")
    
    try:
        choice = int(input(f"\n–í—ã–±–µ—Ä–∏ —á–∞—Ç (1-{min(10, len(chats))}): "))
        if 1 <= choice <= min(10, len(chats)):
            selected_chat = chats[choice - 1]
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
            limit = int(input("–°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø—Ä–æ–≤–µ—Ä–∏—Ç—å? (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 50): ") or "50")
            messages = await parser.parse_chat_messages(selected_chat['id'], limit)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ—Å–æ–≤—ã–µ
            voice_messages = []
            for msg_data in messages:
                # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
                # –≠—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ–¥–∏–∞-–æ–±—ä–µ–∫—Ç–æ–≤
                pass
            
            print(f"üé§ –ù–∞–π–¥–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {len(voice_messages)}")
            
            if voice_messages:
                confirm = input("–ù–∞—á–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é? (y/N): ").strip().lower()
                if confirm in ['y', 'yes', '–¥–∞']:
                    results = await transcriber.transcribe_voice_messages(parser.client, voice_messages)
                    
                    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
                    print(f"üé§ –í—Å–µ–≥–æ –≥–æ–ª–æ—Å–æ–≤—ã—Ö: {results['total_voice_messages']}")
                    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {results['successfully_transcribed']}")
                    print(f"‚ùå –û—à–∏–±–æ–∫: {results['failed_transcriptions']}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    import json
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"voice_transcriptions_{timestamp}.json"
                    filepath = os.path.join(config.OUTPUT_DIR, filename)
                    
                    with open(filepath, 'w', encoding='utf-8') as f:
                        json.dump(results, f, ensure_ascii=False, indent=2)
                    
                    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {filename}")
            else:
                print("üì≠ –ì–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
    except ValueError:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        transcriber.cleanup_temp_files()